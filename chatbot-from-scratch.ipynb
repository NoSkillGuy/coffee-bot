{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Chatbot from scratch (without using any 3rd party API)\n",
    "\n",
    "Train an NLP that identifies the intent. \n",
    "\n",
    "Here's how a sample conversation needs to go. I'll refer to the coffee bot as Alex as that makes things easier.\n",
    "- Me: Hello!\n",
    "- Alex: Hi, what is your name?\n",
    "- Me: I'm Surya.\n",
    "- Alex: What do you want to have?\n",
    "- Me: I'd like a latte.\n",
    "- Alex: Thanks for ordering a latte, you'll have it in a few minutes.\n",
    "- Me: Thank you.\n",
    "\n",
    "\n",
    "\n",
    "Few use cases:\n",
    "- Greetings, finding name\n",
    "    - I'm Surya.\n",
    "    - Raju.\n",
    "    - My name is Sandeep.\n",
    "- Ordering \n",
    "    - Would like something to eat\n",
    "    - Show me the menu\n",
    "    - Can I have a latte? \n",
    "- Cancelling\n",
    "- Identifying the difference of a snack & ordering a drink."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the use of NLTK POS tagger for identifying intent\n",
    "\n",
    "In the ideal scenario that this works perfectly, we will not need any training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Different ways people respond to a question about their name\n",
    "responses_name = [\"I am Surya.\", \"Raju.\", \"My name is Sandeep.\", \"Surendra.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I', 'PRP'), ('am', 'VBP'), ('Surya', 'NNP'), ('.', '.')]\n",
      "[('Raju', 'NNP'), ('.', '.')]\n",
      "[('My', 'PRP$'), ('name', 'NN'), ('is', 'VBZ'), ('Sandeep', 'NNP'), ('.', '.')]\n",
      "[('Surendra', 'NNP'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "# Tokenizing, tagging and displaying\n",
    "print(nltk.pos_tag(word_tokenize(responses_name[0])))\n",
    "print(nltk.pos_tag(word_tokenize(responses_name[1])))\n",
    "print(nltk.pos_tag(word_tokenize(responses_name[2])))\n",
    "print(nltk.pos_tag(word_tokenize(responses_name[3])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, in each of the cases, name is always classified as \"NNP\". So the word in the sentence whose POS is tagged as \"NNP\" can be assumed as the person's name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NNP: noun, proper, singular\n",
      "    Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos\n",
      "    Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA\n",
      "    Shannon A.K.C. Meltex Liverpool ...\n"
     ]
    }
   ],
   "source": [
    "# Use this command to understand more about each tag\n",
    "nltk.help.upenn_tagset('NNP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, this isn't robust. Enough, just adding full stops changes how NLTK tags the words as shown below. This is not what we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I', 'PRP'), ('am', 'VBP'), ('Surya', 'JJ')]\n",
      "[('Raju', 'NN')]\n",
      "[('My', 'PRP$'), ('name', 'NN'), ('is', 'VBZ'), ('Sandeep', 'JJ')]\n",
      "[('Surendra', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "# Different ways people respond to a question about their name\n",
    "responses_name2 = [\"I am Surya\", \"Raju\", \"My name is Sandeep\", \"Surendra\"]\n",
    "\n",
    "# Tokenizing, tagging and displaying\n",
    "print(nltk.pos_tag(word_tokenize(responses_name2[0])))\n",
    "print(nltk.pos_tag(word_tokenize(responses_name2[1])))\n",
    "print(nltk.pos_tag(word_tokenize(responses_name2[2])))\n",
    "print(nltk.pos_tag(word_tokenize(responses_name2[3])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:** NLTK's POS tagger is pretty bad when directly used. We need something better.\n",
    "\n",
    "For better tagging, Stanford's NER (https://nlp.stanford.edu/software/CRF-NER.shtml) can be used, but I don't think that'll give the accuracy we need either."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using opennlp.apache.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
